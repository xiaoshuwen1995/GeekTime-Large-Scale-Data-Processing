# 大规模数据处理实战-04 | 分布式系统（上）：学会用服务等级协议SLA来评估你的系统

在硅谷一线大厂所维护的系统服务中，我们经常可以看见 SLA 这样的承诺。

例如在谷歌的云计算服务平台 Google Cloud Platform ，平台写着“99.9% Availability”这样的承诺。要理解这个承诺是什么意思，首先需要了解到底什么是 SLA。

SLA（Service-Level Agreement），也就是服务等级协议，指的是系统服务提供者（Provider）对客户（Customer）的一个服务承诺。这是衡量一个大型分布式系统是否“健康”的常见方法。

因为 SLA 是一种服务承诺，所以指标可以多种多样。根据我的实践经验，给你介绍最常见的四个 SLA 指标，可用性、准确性、系统容量和延迟。

## 1、可用性（Availabilty）

可用性指的是系统服务能正常运行所占的时间百分比。如果我们搭建出拥有“100％可用性”的系统服务，那就意味着这个系统在任何时候都能正常运行。是不是很完美？但真要实现这样的目标其实非常困难，并且花费的成本也会很高。

对于许多系统而言，四个 9 的可用性（99.99％ Availability，或每年约 50 分钟的系统中断时间）即可以被认为是高可用性（High availability）。

一开始所提到的“99.9% Availability”，真实含义指的是一天当中系统服务将会有大约 86 秒（(24 × 60 × 60 × 0.001) = 86.4 秒）的服务间断期。服务间断也许是因为系统维护，也有可能是因为系统在更新升级系统服务。

## 2、准确性（Accuracy）

准确性指的是我们所设计的系统服务中，是否允许某些数据不准确，或者丢失。如果允许这样的情况发生，用户可以接受的概率（百分比）是多少。

不同的系统平台可能会用不同的指标去定义准确性。很多时候，系统架构会以错误率（Error Rate）来定义这一项 SLA。错误率计算可以用导致系统产生内部错误（Internal Error）的有效请求数，除以这期间的有效请求总数。

![img](https://static001.geekbang.org/resource/image/16/26/16c92cc68b462d469fb535aaa08b8d26.jpg)

准确性在不同场景下可以具有不同定义。Google Cloud Platform 的 SLA 中，准确性被定义为：每个月系统的错误率超过 5% 的时间要少于 0.1%，以每分钟为单位来计算。而亚马逊 AWS 云计算平台中，准确性的定义稍微不一样：以每 5 分钟为单位，错误率不会超过 0.1%。

错误率可以被用来定义系统的准确性，但具体到评估系统的准确性，一般采用性能测试（Performance Test）或者是查看系统日志（Log）两种方法。

## 3、系统容量（Capacity）

在数据处理中，系统容量通常指的是系统能够支持的预期负载量是多少，一般会以每秒的请求数（QPS （Queries Per Second）或RPS（Requests Per Second））为单位来表示。

给自己设计的系统架构定义出准确的 QPS ，可以有下面这几种方式。

1. 第一种，是设置**限流（Throttling）**。

Java 编程能使用 Google Guava 库中的 RateLimiter 类来定义每秒最多发送多少请求到后台处理。如果每台服务器都被定义了一个每秒最多处理 1000 个请求的 RateLimiter，在最理想的情况下，N台服务器的 QPS 可以达到 1000 * N。

这里要注意的雷区是，请求数数量设置并非越多越好。每台服务器的内存有限，过多的请求堆积在服务器，可能会导致内存溢出（Out-Of-Memory）的异常发生。所有请求所需占用的内存超过了服务器能提供的内存，从而会让整个服务器崩溃。

2. 第二种，是在系统交付前进行**性能测试（Performance Test）**。

我们可以使用 Apache JMeter 或 LoadRunner 等工具对系统进行性能测试，这类工具可以测试出系统在峰值状态下可以处理的 QPS 是多少。

当然了，这里也是有雷区的。有的开发者可能使用同一类型的请求参数，导致后台服务器在多数情况下命中缓存（Cache Hit），这个时候得到的 QPS 可能并不真实。打个比方，服务器处理请求的正常流程需要查询后台数据库，得到数据库结果后再返回给用户，这个过程平均需要 1 秒。在第一次拿到数据库结果后，这个数据就会被保存在缓存中。如果后续的请求都使用同一类型的参数，导致结果不需要从数据库而是直接从缓存中得到，这个过程只需要 0.1 秒。那这样，我们所计算出来的 QPS 就会比正常的高出 10 倍。所以在生成请求的时候，要格外注意请求的参数与系统的缓存。

3. 第三种，是对系统在实际使用时产生的**日志分析（Log）**。

系统上线使用会产生日志文件，这些日志文件会记录每个时刻产生的请求。系统每天在最繁忙时刻所接收到的请求数，可以用来计算出系统可以承载的 QPS。

不过，这种方法不一定可以得到系统可以承载的最大 QPS。因为系统在最繁忙时收到的请求数，可能会远低于饱和容量。所以分析系统日志计算出来的 QPS， 并不一定是服务器能够承载的最大 QPS。

想要得到系统能承受的最大 QPS，更多的是性能测试和日志分析相结合的手段。

## 4、延迟（Latency）

延迟指的是系统从收到用户请求到响应这个请求的时间间隔。系统的 SLA 往往会有 p95 或者是 p99 这类的延迟声明。

这里的 p 是 percentile，指的是百分位。一个系统的 p95 延迟是 1 秒的话，那就表示这个系统 95% 个请求的响应时间会少于 1 秒，而剩下的 5% 个请求响应时间会大于 1 秒。

延迟这项指标在 SLA 中直接与用户体验相关，可以通过系统优化来减少。优化的方法很多，例如在将数据库中内容放进缓存（Cache）时，可以通过改进缓存策略从而提高缓存命中率，也可以通过优化数据库的 Schema 或者索引（Index）来降低 p95 或 p99 延迟。

当 p95 或者 p99 过高时，总会有 5% 或者 1% 的用户抱怨产品的用户体验太差，这是要通过优化系统来避免的。

## 小结

当系统架构在不停迭代的时候，有了一个明确的 SLA，我们就可以确定下一代系统架构的改进目标，以及评估优化好的系统架构是否比上一代更加优秀。

我们通常会使用可用性、准确性、系统容量、延迟这四个指标来定义系统架构的 SLA。



这个SLA和一般服务监控指标 RED 原则有点像
R rate 请求速率 qps
E errors 错误数错误率
D duration 延迟
再加一个 服务可用性指标等级 就是今天讲的服务等级了