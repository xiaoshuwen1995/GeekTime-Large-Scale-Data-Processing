# 大规模数据处理实战-03 | 大规模数据处理初体验：怎样实现大型电商热销榜？

我在 Google 面试过很多优秀的候选人，普通编程问题的coding应用能力很强，算法和数据结构也应用得不错。可是当我追问数据规模变大时该怎么设计系统，他们却说不出所以然来。

缺乏**必备的规模增长的技术思维（mindset of scaling）**，会限制这些候选人的职业成长。

## 小规模的经典算法

怎样设计一个系统，根据销售记录统计去年销量前 10 的商品？这个问题的解法分为两步：

第一步，统计每个商品的销量。可以用哈希表（hashtable）数据结构来解决，是一个 O(n) 的算法，例如 n 是 1000 亿。

第二步，找出销量前十，可以用经典的 Top K 算法，也是 O(n) 的算法。

在小规模系统中，我们确实完全可以用经典简洁的算法来解决。随着系统尺度的变大，很多方法就不再适用。

【比如，在小尺度经典物理学中适用的牛顿力学公式是这样的：
$$
F=ma
$$
这在高速强力的物理系统中就不再适用，在狭义相对论中有另外的表达。

![img](https://static001.geekbang.org/resource/image/2c/f7/2c59194f8bebaecd88f5942bcccf75f7.png)

在社会系统中也是一样，管理 10 人团队和治理 14 亿人口的国家，复杂度也不可同日而语。】

具体在我们这个问题中，当数据规模从GB增长到TB时，算法会遇到哪些问题呢？

第一，内存占用问题。对于 TB 级的交易记录数据，很难用单台计算机容纳这么大的哈希表。可能想到不用哈希表去统计商品销售量了，而是把销量计数放在磁盘里完成。比如，就用一个 1000 亿行的文件或者表，然后再把销量统计结果一行一行读进后面的堆树 / 优先级队列。理论上听起来不错，实际上是否真的可行呢，那我们看下一点。

第二，磁盘 I/O 等延时问题。当数据规模变大，我们难以避免地需要把一些中间结果存进磁盘，以应对单步任务出错等问题。一次磁盘读取大概需要 10ms 的时间。如果按照上一点提到的文件替代方法，因为我们是一个 O(n * log k) 的算法，就需要 10ms * 10^9 = 10 ^ 7 s = 115 天的时间，是完全不现实的。

这些问题怎么解决呢？当单台机器已经无法适应我们数据或者问题的规模，我们需要做的就是横向扩展。

## 大规模分布式解决方案

依然延续之前的两步思路，我们只需要把每一步简单的函数算法，升级为计算集群的分布式算法。

![img](https://static001.geekbang.org/resource/image/3e/af/3eaea261df4257f0cff4509d82f211af.png)

### 统计每个商品的销量

我们需要的第一个计算集群，就是统计商品销量的集群。例如，每次能处理 1 万条销售记录的1000台机器。对于每台机器而言，它的单次处理又回归到了我们熟悉的传统算法，数据规模大大缩小。

例如下图每台机器的输入是 2 条销售记录，输出是产品销量计数。

![img](https://static001.geekbang.org/resource/image/8e/8a/8eeff3376743e886d5f2d481ca8ddb8a.jpg)

### 找出销量前 K

我们需要的第二个计算集群，则是找出销量前十的集群。这里我们先把问题抽象为找出销量前 K 的产品。在上一个统计销量集群得到的销量统计数据输出，将会是我们这个处理流程的输入。我们需要做的是分布在各个机器的产品销量汇总。

下图示例是 K = 1 的情况，每台机器按照product_id 分组。先把所有 product_id 的销量相加，再输出自己机器上销量最高（K=1）的商品。

![img](https://static001.geekbang.org/resource/image/38/fc/38933e25ca315bd56321753573d5bbfc.jpg)

### 汇总最终结果

到了最后一步，是汇总“销量前 K 集群”中的结果。这一步从所有候选者中找出真正的销量前 K=1 的商品，因此完全可以用单一机器解决。

例子中实际做的就是这 1000 台机器的结果汇总，规模足够小。

![img](https://static001.geekbang.org/resource/image/ca/ab/cab28c9e3ba9031072a4e6949328bbab.jpg)

## 大规模数据处理框架的功能要求

大规模数据处理框架，两个最基本的需求是：

1. 高度抽象的数据处理流程描述语言。作为运维管理者，肯定不想再逐一配置分布式系统的每台机器。作为框架使用者，也希望能够用简单的几行代码把业务逻辑描述清楚。
2. 分配数据处理流程任务的自动优化。支撑这个框架的引擎需要足够智能，可以减少需要手动配置的系统，实现自动任务分配。

## 小结

这一讲中，我们粗浅地分析了一个电商排行榜的数据处理例子。从 GB 数据到 TB 数据，我们从小规模算法升级到了分布式处理的设计方案；从单一 TB 数据场景到 1000 个应用场景，我们探索了大规模数据处理框架的设计。这些都是为了帮助你更好地理解后面所要讲的所有知识。比如，为什么传统算法不再奏效？为什么要去借助抽象的数据处理描述语言？希望在后面的学习过程中，你能一直带着这些问题出发。