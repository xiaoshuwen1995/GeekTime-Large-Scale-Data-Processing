# 38 | 大规模数据处理在深度学习中如何应用？

![img](https://static001.geekbang.org/resource/image/61/94/61410804678a8525c75991e9fb6dc694.png)

## 大规模数据在深度学习发展中扮演的角色

事实上，类似于模拟神经网络的计算机方法早在 20 世纪 60 年代就被提出来了。

正是因为强大的计算能力和大规模数据突然变得可获得，人们一下子发现曾经遥不可及的神经网络方法真的可以被计算了，才引发了深度学习的爆发性发展。

即使是现在也是如此，在数据量并不充足的人工智能任务上，人们会发现还是传统方法表现更好，然而一旦数据量上来了，深度学习就会碾压式地击败所有传统方法。

以大规模数据驱动的深度学习将是一次不可逆的影响深远的技术变革。

我们看一个技术的影响力，就是看这个技术能够解决哪些曾经不能解决的问题。而深度学习技术所能解决的新问题，几乎涵盖了人类社会发展的各个方面。

一个深度学习驱动的产品周期一般按时间顺序分为这样几个阶段：

1. 数据搜集整理；
2. 深度学习模型开发；
3. 部署和测试深度学习模型；
4. 形成数据闭环反馈不断优化深度学习模型。

## 数据搜集整理 (Data Curation)

数据搜集整理就是针对你需要训练的深度学习问题收集所需要的数据。

数据的搜集整理是任何 AI 系统开发的第一步，可以说没有数据就没有 AI。要注意，并不是只有监督学习需要高质量的数据，实际上无监督学习也需要高质量的数据。

抛开这些非技术因素不谈，数据搜集整理的技术复杂度也是非常高。我们往往用 data massage——给数据按摩，来形容数据搜集整理技术工作是一份并不容易的，十分需要技巧和力量的工作。

因为你的数据来源会非常多，每个数据源的格式可能都不一样，不同数据源提供的数据种类也会有不同，数据源直接甚至可能会相互矛盾。在实际应用中，数据搜集整理的技术部分经常是由很多个大规模数据处理流水线组成。

## 深度学习模型开发 （Modeling）

看到这，你可能会觉得：深度学习的模型开发阶段是不是总算没有数据处理什么事了？看起来都是算法啊，数学啊？完全不是的。当我们在实验深度学习模型时候，许多时间都花在了数据处理上。经常要做的事情是，先去分析一下拿到手上的样本数据。

除了数据分析以外，许多深度学习模型的架构设计都需要大规模的数据处理能力。

## 部署和测试深度学习模型 （Deployment）

部署和测试深度学习模型，其实就是把模型工程化为一个提供结果预测的服务。这样的服务，本质上就是一个数据处理的流水线，它可以是批处理流水线，也可以是流处理流水线。

## 形成数据闭环反馈不断优化深度学习模型（Feedback and improvement)

深度学习产品上线后，依然需要大规模数据处理技术。

像这样的功能上线后，你怎样评估这个深度学习模型的效果呢？你需要去跟踪用户与这个功能的交互。通过这些追踪的用户行为，你就能利用大规模的数据处理技术，不断地为你的深度学习模型提供更多现实的数据，去进一步训练改进模型。也能利用用户行为去评估当前模型的表现。