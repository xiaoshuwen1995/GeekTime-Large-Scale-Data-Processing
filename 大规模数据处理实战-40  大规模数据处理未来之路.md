大规模数据处理技术是在放眼未来的几十年中都依然会是炙手可热的一项技术，不会被淘汰。

## 技术迭代带来的烦恼

Spark 这个计算框架2009 年在加州伯克利大学的 AMPLab 实验室诞生，2010 年正式开源了，2014 年成为了 Apache 的顶级项目。

Spark 的数据处理效率远在 Hadoop 之上，这是经过业界验证的。

如果放弃现有的技术框架，就需要重新花费大量时间去学习新的数据处理框架。对于工程师来说，平时本来就有着做不完的任务和业绩压力，还需要抽空学习新的技术和进行代码的迁移，新增压力和负担。

当然，还有一种做法是保持现有的技术框架，不断优化现有基础设施，并且寄希望于老框架可以有新的功能发布让其性能得以提高。

当有新的技术框架出现的时候，工程师就会陷入一个选择的困难：是直接抛弃原有的技术架构，还是花大量时间去做技术迁移。

 Beam 模型可以避免这个烦恼。如果想要完成底层处理框架的迁移，只需要更改一些 Runner 的接口就可以了。