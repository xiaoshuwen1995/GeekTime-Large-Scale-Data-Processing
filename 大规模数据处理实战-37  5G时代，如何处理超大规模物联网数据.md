# 37 | 5G时代，如何处理超大规模物联网数据

Spark 在 MapReduce 的基础上不断改进，在批处理这方面有良好的性能，在流处理上也在不断提高。Apache Beam 更是一个统一批处理和流处理的框架。

正如我在开篇词中写到的，我理想中的专栏是一份与你一同成长的计划。虽然我们已经对当下流行的技术有了深入的了解，但是作为一名架构师，你的目光一定要放长远，要时刻对未来 5～10 年，乃至 20 年的新问题和技术发展方向保持了解，不能固步自封，只满足于现状。毕竟，我们的征途是星辰大海。

## 什么是物联网？

物联网（Internet of Things）的功能，可以认为是“使用嵌入在物理环境中的网络连接设备，来改进现有流程，或启用以前无法实现的新场景”。这些设备或事物连接到网络后，可以提供它们使用传感器从环境中收集的信息，或允许其他系统通过执行器连接，并作用于现实世界。

想象一下，未来我们身边的所有物体，都有可能连入互联网，我们的生活将变得无比便捷。每个设备都能将来自现实世界的有价值信息转换为数字数据，从而有效改善人类与各类产品的交互方式。

物联网的世界充分体现了大规模数据的四个特点——多样性、大规模、高速率和真实性。

1. 物联网可以被广泛应用在生活的各方各面，比如智能家居、智能交通、智能工厂、智能医院、智能物流等。

2. 大规模之所以说物联网数据规模庞大，是因为它的节点是海量的，它不像互联网，局限于手机或者电脑。而且这些设备是 24 小时不间断地提供数据的，数据的生成频率远高于互联网。
3. 物联网中的数据速率比常见的大数据处理场景要更高。由于前面数据“大规模”的特点，物联网要求数据处理中心能处理更多的数据。同时，为了满足物联网的实时响应，数据的传输速率也要更高才行。

4. 真实性我们都知道，物联网的数据来源于真实世界，而且要根据数据分析处理后的结果，对真实世界中的设备发送指令采取相应的操作，最终会作用于真实世界。所以，物联网对数据真实性要求很高。

## 处理物联网数据的架构

一个基本的物联网数据处理 pipeline 就如下图所示：

![img](https://static001.geekbang.org/resource/image/03/27/03b8920e39c1ef8f7683e3342324b027.png)

你可以看到，在这个 pipeline 中，各个设备终端不断地向数据接收层发送数据。在这一层，数据被清洗，并且转换为统一的格式，然后发送到数据分析层进行分析。在分析过后，处理过的数据可以被存储下来。基于存储的数据，我们可以创建各种 dashboard 来展示，这也方便管理人员直观地观察数据。

在实际应用中，物联网的数据处理场景分不同的类型。有的场景数据量小、处理简单，但是对实时性要求高；有的场景数据量大，处理比较复杂，而且需要综合历史数据。

基于这两种分类，有人提出了“Device-Edge-Cloud”（设备 - 边缘 - 云）的架构，即把简单的、需要实时计算和分析的过程放到离终端设备更近的地方，如设备本身、网关或者服务器，以保证数据数据处理的实时性，同时也减少数据传输的风险，即我们常听说的边缘计算；把复杂的、需要存储的数据处理放在 Cloud 上。这样可以大大加快简单操作的分析和响应速度。

![img](https://static001.geekbang.org/resource/image/1c/2f/1cc5b49b4c2ca6b0b794912694e2fb2f.png)

## 思考题

都说在 5G 时代，边缘计算是一个非常重要的技术。你能去了解一下边缘计算，然后告诉我为什么可以这么说吗？

如果将所有设备看作是物联网集群中的节点的话，数据的计算处理在本地完成，即提高了数据计算的实时性，又减小云端压力，边缘节点只需定期向云端同步必要的信息即可。